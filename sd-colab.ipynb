# インストール
!pip install --upgrade diffusers transformers scipy

# https://huggingface.co/CompVis/stable-diffusion-v1-4 利用規約に同意が必要

YOUR_TOKEN="(HuggingFaceでアカウントを作ってトークンを取得して、張り付ける）"
import os
import datetime
import torch
from diffusers import StableDiffusionPipeline
model_id = "CompVis/stable-diffusion-v1-4"
pipe = StableDiffusionPipeline.from_pretrained(model_id, 
  torch_dtype=torch.float16, revision="fp16", use_auth_token=YOUR_TOKEN)  
pipe = pipe.to("cuda")

# ここから先は自分の使いやすいように書き換えてください
# 乱数のシード値。必要なときはDream Studioからもってきましょう。

seed = 1317567826
generator = torch.Generator("cuda").manual_seed(seed)

# プロンプト

prompt = "playing hatsune miku in minecraft trending on Pixiv HQ"

# Google Driveと連携

from google.colab import drive
drive.mount('/content/drive')
path = f"/content/drive/MyDrive/MyStableDiffusion/"
with torch.autocast("cuda"):
  image = pipe(prompt, generator=generator)["sample"][0]

# 画像を保存する（日付時刻をつかって重複回避しています）

is_file = os.path.isfile(path+prompt+".png")
if is_file:
    d = datetime.datetime.now().strftime('%Y-%m-%d-%H%M%S')
    image.save(path+d+" - "+str(seed)+" "+prompt+".png")
else:
    image.save(path+str(seed)+" " +prompt+".png")
//}

//image[CoCode][Google Colabでコードを張り付けたところ][scale=0.5]{
//}

左上の再生ボタン「▶」を押すことで、コードが走り始めます。

コードの冒頭にトークンを設定する箇所があります。
Hugging Faceのサイトからトークンを取得して、貼り付ける必要があります。
//blankline
 * Hugging Faceのサイトからトークンを取得
 ** @<href>{https://huggingface.co/settings/tokens}


こちらの設定画面からクリップボード経由で取得できます。
また、事前にStable Diffusionのライセンスに合意している必要があります。

//image[CoCode4][設定を変更してGPUを使用します][scale=0.5]{
//}

また、途中でエラーで止まることがあります。
多くの場合は「GPUを利用していない」か、複数起動しているケースです。
右側の「セッションの管理」、「ランタイムのタイプを変更」から「ハードウェアアクセラレータ」で「GPU」を明示的に選択しましょう（無料の利用枠でもGPUが選択できる、ありがたい……！）。
再度、左上の再生ボタン「▶」を押すことでコードが走り始めます。

//image[CoCode5][ドライブのマウント][scale=0.5]{
//}

保存先のドライブをマウントしましょう。
このコードではこちらのパスにファイルを保存していますので、事前に「MyStableDiffusion」というフォルダを作っておく必要があります。
また、マウント状態は左側のフォルダアイコンから確認できます。

Colabは成功したステップごとに、確認しながらコードを走らせることができます。
一発で動くコードにすることもできますし、ステップごとにばらしていくこともできます。

Phthyonの勉強にもなりますね！

//image[CoCode6][完全無料でColab上でStable Diffusionによる画像生成ができました][scale=0.5]{
//}

これで、完全無料でColab上でStable Diffusionによる画像生成ができました。

== DreamStudioとの互換性を確認する実験

試しに、DreamStudioのランダムシードを利用して、ColabでのStable Diffusionとの結果の違いを比較してみました。
DreamStudioのシード値（この場合 @<tt>{1317567826}）は、DreamStudioで、イイ感じに出力できるプロンプト文字列とともに手に入れたシード値です。
このシード値とプロンプトを使って、上記のコードで、画像を生成してみます。
このふたつの環境で、同じような画像が生成されれば大成功です……！

//image[ColabResults][Dream StudioとColabで同じシードから探求できるようになった]{
//}

同じような画像が生成できました！大成功です。

これで、DreamStudioと同じように、ブラウザーだけで、Google Colab上で特徴だけを残して無料で探究するパイプラインができました……！
DreamStudioより使いやすく、探求コストを下げつつ画質向上できます。
そろそろシード値に愛着を持つようになってきたのではないでしょうか？

== 他のモデルを利用する

Stable Diffusionをファインチューニング（転移学習）した、様々なモデルが登場しています。
本書ではそのすべてを紹介することはできませんが、Colabでの様々なコードが紹介されています。
筆者は同時に複数の画像やバリエーションを生成するスクリプトを組んでいます。

//blankline

 * 参考にした6uclz1さんのコード 
 ** @<href>{https://zenn.dev/6uclz1/articles/d7736b06d24f1a}

//list[WaifuDiffusion][Waifu DiffusionをGoogle Colabで動かすサンプル(前半)]{
# パッケージのインストール

!pip install diffusers==0.2.4 transformers scipy ftfy python-ulid
import torch
from torch import autocast
from diffusers import StableDiffusionPipeline
import uuid
model_id = "hakurei/waifu-diffusion"
device = "cuda"
pipe = StableDiffusionPipeline.from_pretrained(
  model_id, torch_dtype=torch.float16, revision='fp16')
pipe = pipe.to(device)

# NSFWの制限を外す

pipe.safety_checker = lambda images, **kwargs: (images, False)

# 便利関数を準備

from PIL import Image
from torch import autocast
import uuid
from ulid import ULID

# 画像を繋げる関数

def image_grid(imgs, rows, cols):
    assert len(imgs) == rows*cols
    w, h = imgs[0].size
    grid = Image.new('RGB', size=(cols*w, rows*h))
    grid_w, grid_h = grid.size
    for i, img in enumerate(imgs):
        grid.paste(img, box=(i%cols*w, i//cols*h))
    return grid

# Google Drive と連携

from google.colab import drive
drive.mount('/content/gdrive')

## ↑ここまでをStep1にするといい ↓ここからがStep2
//}

ここまでで、HuggingFaceのTokenとドライブマウントまで一気に実行できます。
成功するとGoogle Driveへのアクセスを確認されますので、お使いのアカウントでマウントしましょう。

@<tt>{/content/gdrive/MyDrive/Colab/StableDiffusion} にディレクトリーを作成しておくのを忘れずに。

//list[WaifuDiffusion][Waifu DiffusionをGoogle Colabで動かすサンプル(後半)]{
# Drive接続が終わってから実施する

num_images = 3

# ここに呪文を入れる（何でもいいです）

prompt_text = "a cover illustration of beautiful drawing goddess with long silver hair odd eyes (blue, red) posing with a painting brush and béret in a cyber space, looking up the camera, emotional, dramatic lighting, very colorful, high contrasthigh detail, high quarity, trending on Game Developer, style by alfons mucha"
prompt = [prompt_text] * num_images
steps = 150

# 3回同じ処理をしてメモリー制限を回避している

with autocast("cuda"):
  images = pipe(prompt, num_inference_steps=steps)["sample"]
with autocast("cuda"):
  images.extend(pipe(prompt, num_inference_steps=steps)["sample"])
with autocast("cuda"):
  images.extend(pipe(prompt, num_inference_steps=steps)["sample"])
ulid = ULID()
file_name = str(ulid)
file_path = "/content/gdrive/MyDrive/Colab/WaifuDiffusion/"

# よくできた画像の呪文を忘れないようにファイル出力して表示する

with open(file_path + file_name + '.txt', 'w') as f:
  f.write(prompt_text)

# 3 x 3 の画像を出力する

grid = image_grid(images, rows=3, cols=3)
grid.save(file_path + file_name + '.png')

# 作製された9枚の画像を一つずつ出力する

i = 1
for image in images:
  image.save(file_path + file_name + '_' + str(i) + '.png')
  i = i + 1
grid
//}

こちらのコードはColabの画面内に3x3で9画像を表示し、その個別画像とプロンプトも生成することができます。
